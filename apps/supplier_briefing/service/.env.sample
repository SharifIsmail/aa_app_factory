# Authentication token for AA service
SERVICE_AUTHENTICATION_TOKEN=your_authentication_token

# API client URL
SERVICE_INFERENCE_API_URL=https://inference-api.customer.pharia.com/

#### Other App specific variable required. Make sure to define them on GitHub and on the build-and-push job as well.  ####

# Used for previewing applicaton's UI on the assistant
VITE_SERVICE_BASE_URL=http://localhost:8080

# Authorization URL, set to "none" for no authorization service, otherwise to "https://pharia-iam.customer.pharia.com/"
SERVICE_PHARIA_AUTH_SERVICE_URL="https://pharia-iam.customer.pharia.com/"

# Pharia Data API URL
SERVICE_PHARIA_DATA_URL="https://pharia-data-api.customer.pharia.com/"

# Default model for LLM completions
SERVICE_COMPLETION_MODEL_NAME=llama-3.3-70b-instruct

# Studio information for tracing
SERVICE_STUDIO_URL=https://pharia-studio.customer.pharia.com/
SERVICE_STUDIO_PROJECT_NAME=supplier-briefing

SERVICE_TARGET_OUTPUT_LANGUAGE=german

# Telemetry for debugging agents: disabled, pharia_studio, phoenix
SERVICE_AGENT_TELEMETRY=disabled

SERVICE_ENABLE_DATA_PREPARATION=False

# Thinking end tag for reasoning models to strip completion by
SERVICE_THINKING_END_TAG=</think>

SERVICE_ENABLE_LLM_CACHING=True
SERVICE_ENABLE_LLM_MESSAGE_SAVING=False

OPENAI_API_KEY=your_openai_api_key

# Vertex AI Credentials as json (note the quotation marks), see 1password
SERVICE_VERTEX_AI_CREDENTIALS='{"type": "service_account", "project_id": ... }'

SERVICE_MODEL_QUERY_AGENT=vertex_ai/gemini-2.5-pro
SERVICE_MODEL_DATA_ANALYSIS_AGENT=vertex_ai/gemini-2.5-pro
SERVICE_MODEL_LLM_COMPLETION=vertex_ai/gemini-2.5-pro
SERVICE_MODEL_EVALUATION=aleph-alpha/qwen3-30b-a3b-thinking-2507-fp8
SERVICE_MODEL_EXPLAINABILITY=vertex_ai/gemini-2.5-flash
SERVICE_MODEL_WEAK=vertex_ai/gemini-2.5-flash
